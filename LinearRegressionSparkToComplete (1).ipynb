{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegressionSparkToComplete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T2scBLCPSsp"
      },
      "source": [
        "Linear Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKuuJpr3SC6s"
      },
      "source": [
        "Librairies Machine Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6Hl0YE3pRp0",
        "outputId": "0199bcb2-1d6f-4964-eeb8-5eaba2ce7f03"
      },
      "source": [
        "!pip install findspark \n",
        "!pip install pyspark "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b701CLFBpRAt"
      },
      "source": [
        "import pyspark \n",
        "import findspark"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCMrYx5GSCZZ"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XK0Hpa9PoNa"
      },
      "source": [
        "Importer les données sous Spark "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4n5UB2Tpw8E"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"TextClassifier\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGDSfnhgR9kY"
      },
      "source": [
        "dataset = spark.read.csv('/content/sample_data/BostonHousing.csv',inferSchema=True, header =True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f35ZeMMHSK9C",
        "outputId": "e10ecaa9-e492-4397-e14f-1e51de024b51"
      },
      "source": [
        "dataset.printSchema()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- crim: double (nullable = true)\n",
            " |-- zn: double (nullable = true)\n",
            " |-- indus: double (nullable = true)\n",
            " |-- chas: integer (nullable = true)\n",
            " |-- nox: double (nullable = true)\n",
            " |-- rm: double (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- dis: double (nullable = true)\n",
            " |-- rad: integer (nullable = true)\n",
            " |-- tax: integer (nullable = true)\n",
            " |-- ptratio: double (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- lstat: double (nullable = true)\n",
            " |-- medv: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBqOHkVdSWsD",
        "outputId": "b60766fd-8c16-4c79-9f90-500fe1908440"
      },
      "source": [
        "#Input all the features in one vector column\n",
        "assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')\n",
        "\n",
        "output = assembler.transform(dataset)\n",
        "\n",
        "# (\"Attributes\",\"medv\") => (key,value),  key and value cloud be as complex as you need !!!!\n",
        "finalized_data = output.select(\"Attributes\",\"medv\")\n",
        "\n",
        "finalized_data.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|          Attributes|medv|\n",
            "+--------------------+----+\n",
            "|[0.00632,18.0,2.3...|24.0|\n",
            "|[0.02731,0.0,7.07...|21.6|\n",
            "|[0.02729,0.0,7.07...|34.7|\n",
            "|[0.03237,0.0,2.18...|33.4|\n",
            "|[0.06905,0.0,2.18...|36.2|\n",
            "|[0.02985,0.0,2.18...|28.7|\n",
            "|[0.08829,12.5,7.8...|22.9|\n",
            "|[0.14455,12.5,7.8...|27.1|\n",
            "|[0.21124,12.5,7.8...|16.5|\n",
            "|[0.17004,12.5,7.8...|18.9|\n",
            "|[0.22489,12.5,7.8...|15.0|\n",
            "|[0.11747,12.5,7.8...|18.9|\n",
            "|[0.09378,12.5,7.8...|21.7|\n",
            "|[0.62976,0.0,8.14...|20.4|\n",
            "|[0.63796,0.0,8.14...|18.2|\n",
            "|[0.62739,0.0,8.14...|19.9|\n",
            "|[1.05393,0.0,8.14...|23.1|\n",
            "|[0.7842,0.0,8.14,...|17.5|\n",
            "|[0.80271,0.0,8.14...|20.2|\n",
            "|[0.7258,0.0,8.14,...|18.2|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYrTmwUKUVMr"
      },
      "source": [
        "Comme vous pouvez le constater l'input qu'on va soumettre à Spark is a set of (key,value), rappel du cours, (key,value) may be as complex as you need !!!!!, the key is the set of attribute and the value is the TARGET (variable cible)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hW6JsibUy1R"
      },
      "source": [
        "Machine Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALr_4tr3U3Kk"
      },
      "source": [
        "Diviser dataset en train et test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE5guTn3UxG-"
      },
      "source": [
        "#Split training and testing data\n",
        "train_data,test_data = finalized_data.randomSplit([0.8,0.2])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTsHnzXHU7Fp"
      },
      "source": [
        "Créer le modèle avec le train_data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZsrmo36U7dM"
      },
      "source": [
        "regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
        "\n",
        "#Learn to fit the model from training set\n",
        "regressor = regressor.fit(train_data)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jUQT9k-VYlE"
      },
      "source": [
        "Afficher l'intercept et le coéffcient h(x) = intercept + coef *x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ54zutYViW3",
        "outputId": "9b61be3e-ed93-4e4e-93c6-31dd7c7fe86e"
      },
      "source": [
        "#coefficient of the regression model\n",
        "coeff = regressor.coefficients\n",
        "\n",
        "#X and Y intercept\n",
        "intr = regressor.intercept\n",
        "\n",
        "print (\"The coefficient of the model is : %a\" %coeff)\n",
        "print (\"The Intercept of the model is : %f\" %intr)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The coefficient of the model is : DenseVector([-0.0994, 0.0346, 0.0384, 2.9472, -18.7867, 4.2879, -0.0033, -1.3076, 0.253, -0.0129, -0.8898, 0.0063, -0.4822])\n",
            "The Intercept of the model is : 33.513059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp6ffezfU-42"
      },
      "source": [
        "Prédiction sur l'ensemble de test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjBssc_5VA2O"
      },
      "source": [
        "#To predict the prices on testing set\n",
        "pred = regressor.evaluate(test_data)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbr-6wakVOCx"
      },
      "source": [
        "Afficher le résultat "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ow3AAdDVPZ2",
        "outputId": "83b97211-7378-45e4-d336-e6c0072a6b72"
      },
      "source": [
        "pred.predictions.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+------------------+\n",
            "|          Attributes|medv|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[0.00906,90.0,2.9...|32.2|31.649797119134398|\n",
            "|[0.0136,75.0,4.0,...|18.9|15.370648796311002|\n",
            "|[0.01381,80.0,0.4...|50.0| 40.59673186061093|\n",
            "|[0.01501,90.0,1.2...|50.0|44.836233052674785|\n",
            "|[0.03502,80.0,4.9...|28.5| 33.03532167939657|\n",
            "|[0.0351,95.0,2.68...|48.5| 41.62261968153901|\n",
            "|[0.03584,80.0,3.3...|23.5|29.777329445232272|\n",
            "|[0.03615,80.0,4.9...|27.9|31.398939872906425|\n",
            "|[0.03768,80.0,1.5...|34.6| 34.57409977996163|\n",
            "|[0.03932,0.0,3.41...|22.0| 27.33136045673829|\n",
            "|[0.04113,25.0,4.8...|28.0|28.652014235935944|\n",
            "|[0.04544,0.0,3.24...|19.8|21.912990057967626|\n",
            "|[0.0456,0.0,13.89...|23.3| 26.71267104073081|\n",
            "|[0.0459,52.5,5.32...|22.3|27.075119127052375|\n",
            "|[0.04666,80.0,1.5...|30.3| 32.66586381710843|\n",
            "|[0.05059,0.0,4.49...|23.9|25.196440489005838|\n",
            "|[0.05497,0.0,5.19...|19.0|21.447867254259833|\n",
            "|[0.05561,70.0,2.2...|29.0| 31.95135652531899|\n",
            "|[0.05644,40.0,6.4...|32.4| 36.08853701787283|\n",
            "|[0.0566,0.0,3.41,...|23.6|30.761905070508863|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2QLAoAXVs_C"
      },
      "source": [
        "Evaluer le modèle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBxl3TywVunH",
        "outputId": "41c87518-a4fc-4f24-d3ea-48e8196c9502"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 6.025\n",
            "MSE: 36.295\n",
            "MAE: 3.796\n",
            "r2: 0.621\n"
          ]
        }
      ]
    }
  ]
}